//Scala
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName("Group_By")
  .getOrCreate()

import spark.implicits._


val data = Seq(
    ("Electronics", "Laptop"),
    ("Electronics", "Phone"),
    ("Clothing", "T-Shirt"),
    ("Clothing", "Jeans"),
    ("Furniture", "Chair")
).toDF("category", "product")

val groupByCat = data.groupBy("category").agg(count("product")).alias("count")

groupByCat.show()

//PySpark

%python
from pyspark.sql import SparkSession
from pyspark.sql.functions import *

spark = SparkSession.builder.appName("GroupBy").getOrCreate()

data = [
    ("Electronics", "Laptop"),
    ("Electronics", "Phone"),
    ("Clothing", "T-Shirt"),
    ("Clothing", "Jeans"),
    ("Furniture", "Chair")
]

df = spark.createDataFrame(data, ["category", "product"])

groupByCat = df.groupBy("category").agg(count("product")).alias("count")

groupByCat.show()



